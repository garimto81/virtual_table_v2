#!/usr/bin/env python3
"""
Advanced Meta Agent System - ì—¬ëŸ¬ í•˜ìœ„ ì—ì´ì „íŠ¸ë“¤ì„ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ê³  ì¡°í•©í•˜ëŠ” ë©”íƒ€ ì—ì´ì „íŠ¸

ì£¼ìš” ê¸°ëŠ¥:
1. ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ë§¤ë‹ˆì €
2. ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ ì„ íƒê¸°  
3. í˜‘ì—… ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
4. ë©”íƒ€ ì—ì´ì „íŠ¸ ë¶„ì„ê¸°
5. ìë™ ì—ì´ì „íŠ¸ ì²´ì¸ êµ¬ì„±ê¸°

ì‘ì„±ì: Claude AI Assistant
ë²„ì „: 1.0.0
ìµœì¢… ì—…ë°ì´íŠ¸: 2025-09-19
"""

import asyncio
import json
import logging
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Set, Union
from dataclasses import dataclass, asdict, field
from enum import Enum
import threading
import queue
import uuid
from abc import ABC, abstractmethod
import networkx as nx
import numpy as np

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('meta_agent.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AgentRole(Enum):
    """ì—ì´ì „íŠ¸ ì—­í•  ë¶„ë¥˜"""
    BACKEND_ARCHITECT = "backend-architect"
    PYTHON_PRO = "python-pro"
    FRONTEND_DEVELOPER = "frontend-developer"
    TYPESCRIPT_EXPERT = "typescript-expert"
    TEST_AUTOMATOR = "test-automator"
    QA_ENGINEER = "qa-engineer"
    SECURITY_AUDITOR = "security-auditor"
    PENETRATION_TESTER = "penetration-tester"
    PERFORMANCE_ENGINEER = "performance-engineer"
    DATABASE_OPTIMIZER = "database-optimizer"
    DEPLOYMENT_ENGINEER = "deployment-engineer"
    DEVOPS_EXPERT = "devops-expert"
    SYSTEM_DESIGNER = "system-designer"
    DATA_SCIENTIST = "data-scientist"
    ML_ENGINEER = "ml-engineer"
    UI_UX_DESIGNER = "ui-ux-designer"

class ExecutionMode(Enum):
    """ì‹¤í–‰ ëª¨ë“œ"""
    SEQUENTIAL = "sequential"
    PARALLEL = "parallel"
    PIPELINE = "pipeline"
    ADAPTIVE = "adaptive"

class AgentStatus(Enum):
    """ì—ì´ì „íŠ¸ ìƒíƒœ"""
    IDLE = "idle"
    BUSY = "busy"
    ERROR = "error"
    OFFLINE = "offline"

@dataclass
class AgentCapability:
    """ì—ì´ì „íŠ¸ ì—­ëŸ‰ ì •ì˜"""
    name: str
    skill_level: float  # 0.0 ~ 1.0
    domain: str
    keywords: List[str] = field(default_factory=list)
    dependencies: List[str] = field(default_factory=list)

@dataclass
class SubAgent:
    """í•˜ìœ„ ì—ì´ì „íŠ¸ ì •ì˜"""
    id: str
    role: AgentRole
    name: str
    description: str
    capabilities: List[AgentCapability]
    status: AgentStatus = AgentStatus.IDLE
    load_factor: float = 0.0  # í˜„ì¬ ë¶€í•˜ (0.0 ~ 1.0)
    success_rate: float = 1.0
    average_response_time: float = 0.0
    total_tasks: int = 0
    completed_tasks: int = 0
    failed_tasks: int = 0
    last_activity: datetime = field(default_factory=datetime.now)
    
    def __post_init__(self):
        if not self.capabilities:
            self.capabilities = []

@dataclass 
class TaskDefinition:
    """ì‘ì—… ì •ì˜"""
    id: str
    title: str
    description: str
    priority: int  # 1(ë‚®ìŒ) ~ 10(ë†’ìŒ)
    estimated_duration: int  # ì´ˆ
    required_skills: List[str] = field(default_factory=list)
    required_agents: List[AgentRole] = field(default_factory=list)
    dependencies: List[str] = field(default_factory=list)
    input_data: Dict[str, Any] = field(default_factory=dict)
    output_schema: Dict[str, Any] = field(default_factory=dict)
    timeout: int = 300  # ê¸°ë³¸ 5ë¶„
    retry_count: int = 3

@dataclass
class AgentChain:
    """ì—ì´ì „íŠ¸ ì²´ì¸ ì •ì˜"""
    id: str
    name: str
    description: str
    agents: List[str]  # ì—ì´ì „íŠ¸ ID ìˆœì„œ
    execution_mode: ExecutionMode
    data_flow: Dict[str, str] = field(default_factory=dict)  # ì¶œë ¥->ì…ë ¥ ë§¤í•‘
    conditional_logic: Dict[str, Any] = field(default_factory=dict)
    
@dataclass
class WorkflowExecution:
    """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ìƒíƒœ"""
    id: str
    chain_id: str
    status: str
    start_time: datetime
    end_time: Optional[datetime] = None
    current_agent: Optional[str] = None
    completed_agents: List[str] = field(default_factory=list)
    results: Dict[str, Any] = field(default_factory=dict)
    errors: List[str] = field(default_factory=list)
    metrics: Dict[str, float] = field(default_factory=dict)

class AgentInterface(ABC):
    """ì—ì´ì „íŠ¸ ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    async def execute_task(self, task: TaskDefinition) -> Dict[str, Any]:
        """ì‘ì—… ì‹¤í–‰"""
        pass
    
    @abstractmethod
    async def get_status(self) -> AgentStatus:
        """ìƒíƒœ ì¡°íšŒ"""
        pass
    
    @abstractmethod
    async def get_capabilities(self) -> List[AgentCapability]:
        """ì—­ëŸ‰ ì¡°íšŒ"""
        pass

class MetaAgentSystem:
    """ë©”íƒ€ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ - ì—¬ëŸ¬ í•˜ìœ„ ì—ì´ì „íŠ¸ë“¤ì„ ì¡°í•©í•˜ê³  ê´€ë¦¬"""
    
    def __init__(self):
        self.agents: Dict[str, SubAgent] = {}
        self.agent_chains: Dict[str, AgentChain] = {}
        self.active_workflows: Dict[str, WorkflowExecution] = {}
        self.task_queue = queue.PriorityQueue()
        self.performance_metrics = {}
        self.collaboration_graph = nx.DiGraph()
        self.initialize_agents()
        self.setup_collaboration_patterns()
        
    def initialize_agents(self):
        """í•˜ìœ„ ì—ì´ì „íŠ¸ë“¤ ì´ˆê¸°í™”"""
        logger.info("ğŸ¤– í•˜ìœ„ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹œì‘")
        
        # Python ê°œë°œ ì „ë¬¸ê°€
        python_pro = SubAgent(
            id="python_pro_01",
            role=AgentRole.PYTHON_PRO,
            name="Python ì „ë¬¸ê°€",
            description="Python ê°œë°œ, ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©, ì„±ëŠ¥ ìµœì í™” ì „ë¬¸",
            capabilities=[
                AgentCapability("python_development", 0.95, "backend", 
                               ["python", "django", "fastapi", "flask", "asyncio"]),
                AgentCapability("data_processing", 0.90, "data", 
                               ["pandas", "numpy", "scipy", "data_analysis"]),
                AgentCapability("api_development", 0.88, "backend",
                               ["rest_api", "graphql", "microservices"])
            ]
        )
        
        # ë°±ì—”ë“œ ì•„í‚¤í…íŠ¸
        backend_architect = SubAgent(
            id="backend_arch_01", 
            role=AgentRole.BACKEND_ARCHITECT,
            name="ë°±ì—”ë“œ ì•„í‚¤í…íŠ¸",
            description="ì‹œìŠ¤í…œ ì„¤ê³„, ì•„í‚¤í…ì²˜ íŒ¨í„´, í™•ì¥ì„± ì„¤ê³„ ì „ë¬¸",
            capabilities=[
                AgentCapability("system_design", 0.95, "architecture",
                               ["microservices", "scalability", "distributed_systems"]),
                AgentCapability("database_design", 0.90, "data",
                               ["relational_db", "nosql", "data_modeling"]),
                AgentCapability("api_design", 0.92, "backend",
                               ["rest", "graphql", "api_gateway"])
            ]
        )
        
        # í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì
        frontend_dev = SubAgent(
            id="frontend_dev_01",
            role=AgentRole.FRONTEND_DEVELOPER, 
            name="í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì",
            description="React, Next.js, TypeScript ê¸°ë°˜ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ ì „ë¬¸",
            capabilities=[
                AgentCapability("react_development", 0.93, "frontend",
                               ["react", "nextjs", "jsx", "hooks"]),
                AgentCapability("typescript", 0.90, "frontend",
                               ["typescript", "type_safety", "interfaces"]),
                AgentCapability("ui_components", 0.88, "frontend",
                               ["components", "styling", "responsive"])
            ]
        )
        
        # í…ŒìŠ¤íŠ¸ ìë™í™” ì „ë¬¸ê°€
        test_automator = SubAgent(
            id="test_auto_01",
            role=AgentRole.TEST_AUTOMATOR,
            name="í…ŒìŠ¤íŠ¸ ìë™í™” ì „ë¬¸ê°€", 
            description="ìë™í™” í…ŒìŠ¤íŠ¸, E2E í…ŒìŠ¤íŠ¸, ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì „ë¬¸",
            capabilities=[
                AgentCapability("unit_testing", 0.95, "testing",
                               ["pytest", "jest", "unit_tests", "mocking"]),
                AgentCapability("e2e_testing", 0.90, "testing",
                               ["playwright", "selenium", "cypress"]),
                AgentCapability("performance_testing", 0.85, "testing",
                               ["load_testing", "stress_testing", "benchmarking"])
            ]
        )
        
        # ë³´ì•ˆ ê°ì‚¬ê´€
        security_auditor = SubAgent(
            id="security_audit_01",
            role=AgentRole.SECURITY_AUDITOR,
            name="ë³´ì•ˆ ê°ì‚¬ê´€",
            description="ì½”ë“œ ë³´ì•ˆ ê²€í† , ì·¨ì•½ì  ë¶„ì„, ë³´ì•ˆ ê°€ì´ë“œë¼ì¸ ì ìš©",
            capabilities=[
                AgentCapability("security_audit", 0.92, "security",
                               ["vulnerability_scan", "code_review", "security_patterns"]),
                AgentCapability("penetration_testing", 0.88, "security", 
                               ["pentest", "exploit", "security_testing"]),
                AgentCapability("compliance", 0.85, "security",
                               ["gdpr", "security_standards", "audit"])
            ]
        )
        
        # ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´
        perf_engineer = SubAgent(
            id="perf_eng_01",
            role=AgentRole.PERFORMANCE_ENGINEER,
            name="ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´",
            description="ì„±ëŠ¥ ìµœì í™”, í”„ë¡œíŒŒì¼ë§, ë³‘ëª© ì§€ì  ë¶„ì„ ì „ë¬¸",
            capabilities=[
                AgentCapability("performance_optimization", 0.94, "performance",
                               ["profiling", "optimization", "bottleneck_analysis"]),
                AgentCapability("caching", 0.90, "performance",
                               ["redis", "memcached", "cache_strategies"]),
                AgentCapability("database_optimization", 0.88, "performance",
                               ["query_optimization", "indexing", "database_tuning"])
            ]
        )
        
        # DevOps ì „ë¬¸ê°€
        devops_expert = SubAgent(
            id="devops_exp_01",
            role=AgentRole.DEVOPS_EXPERT,
            name="DevOps ì „ë¬¸ê°€",
            description="CI/CD, ì»¨í…Œì´ë„ˆí™”, ì¸í”„ë¼ ìë™í™” ì „ë¬¸",
            capabilities=[
                AgentCapability("cicd", 0.93, "devops",
                               ["github_actions", "jenkins", "gitlab_ci"]),
                AgentCapability("containerization", 0.91, "devops",
                               ["docker", "kubernetes", "container_orchestration"]),
                AgentCapability("infrastructure", 0.89, "devops",
                               ["terraform", "ansible", "cloud_infrastructure"])
            ]
        )
        
        # ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì „ë¬¸ê°€
        db_optimizer = SubAgent(
            id="db_opt_01",
            role=AgentRole.DATABASE_OPTIMIZER,
            name="ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì „ë¬¸ê°€",
            description="ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ íŠœë‹, ìŠ¤í‚¤ë§ˆ ìµœì í™”, ì¿¼ë¦¬ ìµœì í™”",
            capabilities=[
                AgentCapability("query_optimization", 0.95, "database",
                               ["sql_optimization", "index_tuning", "execution_plans"]),
                AgentCapability("schema_design", 0.90, "database",
                               ["normalization", "denormalization", "schema_optimization"]),
                AgentCapability("database_monitoring", 0.88, "database",
                               ["performance_monitoring", "alerting", "database_health"])
            ]
        )
        
        # ì‹œìŠ¤í…œ ì„¤ê³„ì
        system_designer = SubAgent(
            id="sys_design_01",
            role=AgentRole.SYSTEM_DESIGNER,
            name="ì‹œìŠ¤í…œ ì„¤ê³„ì",
            description="ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„, ê¸°ìˆ  ìŠ¤íƒ ì„ íƒ, í†µí•© ì„¤ê³„",
            capabilities=[
                AgentCapability("architecture_design", 0.94, "architecture",
                               ["system_architecture", "design_patterns", "scalability"]),
                AgentCapability("technology_selection", 0.90, "architecture",
                               ["tech_stack", "tool_selection", "technology_evaluation"]),
                AgentCapability("integration_design", 0.88, "architecture",
                               ["api_integration", "service_integration", "data_flow"])
            ]
        )
        
        # ì—ì´ì „íŠ¸ ë“±ë¡
        for agent in [python_pro, backend_architect, frontend_dev, test_automator,
                     security_auditor, perf_engineer, devops_expert, db_optimizer,
                     system_designer]:
            self.agents[agent.id] = agent
            
        logger.info(f"âœ… {len(self.agents)}ê°œ í•˜ìœ„ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        
    def setup_collaboration_patterns(self):
        """í˜‘ì—… íŒ¨í„´ ì„¤ì •"""
        logger.info("ğŸ¤ í˜‘ì—… íŒ¨í„´ ì„¤ì • ì‹œì‘")
        
        # ë°±ì—”ë“œ ê°œë°œ ì²´ì¸
        backend_chain = AgentChain(
            id="backend_development",
            name="ë°±ì—”ë“œ ê°œë°œ íŒŒì´í”„ë¼ì¸",
            description="ì‹œìŠ¤í…œ ì„¤ê³„ â†’ ë°±ì—”ë“œ ê°œë°œ â†’ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” â†’ ë³´ì•ˆ ê²€í†  â†’ ì„±ëŠ¥ ìµœì í™”",
            agents=["sys_design_01", "backend_arch_01", "python_pro_01", 
                   "db_opt_01", "security_audit_01", "perf_eng_01"],
            execution_mode=ExecutionMode.SEQUENTIAL,
            data_flow={
                "sys_design_01": "backend_arch_01",
                "backend_arch_01": "python_pro_01", 
                "python_pro_01": "db_opt_01",
                "db_opt_01": "security_audit_01",
                "security_audit_01": "perf_eng_01"
            }
        )
        
        # í’€ìŠ¤íƒ ê°œë°œ ì²´ì¸
        fullstack_chain = AgentChain(
            id="fullstack_development",
            name="í’€ìŠ¤íƒ ê°œë°œ íŒŒì´í”„ë¼ì¸",
            description="ì‹œìŠ¤í…œ ì„¤ê³„ì™€ ë°±ì—”ë“œ/í”„ë¡ íŠ¸ì—”ë“œ ë³‘ë ¬ ê°œë°œ í›„ í†µí•© í…ŒìŠ¤íŠ¸",
            agents=["sys_design_01", "backend_arch_01", "python_pro_01", 
                   "frontend_dev_01", "test_auto_01", "security_audit_01"],
            execution_mode=ExecutionMode.PIPELINE,
            data_flow={
                "sys_design_01": "backend_arch_01,frontend_dev_01",
                "backend_arch_01": "python_pro_01",
                "python_pro_01": "test_auto_01",
                "frontend_dev_01": "test_auto_01",
                "test_auto_01": "security_audit_01"
            }
        )
        
        # ì„±ëŠ¥ ìµœì í™” ì²´ì¸
        performance_chain = AgentChain(
            id="performance_optimization",
            name="ì„±ëŠ¥ ìµœì í™” íŒŒì´í”„ë¼ì¸", 
            description="ì„±ëŠ¥ ë¶„ì„ â†’ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” â†’ ì½”ë“œ ìµœì í™” â†’ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸",
            agents=["perf_eng_01", "db_opt_01", "python_pro_01", "test_auto_01"],
            execution_mode=ExecutionMode.SEQUENTIAL,
            data_flow={
                "perf_eng_01": "db_opt_01,python_pro_01",
                "db_opt_01": "test_auto_01",
                "python_pro_01": "test_auto_01"
            }
        )
        
        # DevOps ë°°í¬ ì²´ì¸
        devops_chain = AgentChain(
            id="devops_deployment",
            name="DevOps ë°°í¬ íŒŒì´í”„ë¼ì¸",
            description="ì½”ë“œ ê²€í†  â†’ í…ŒìŠ¤íŠ¸ â†’ ë³´ì•ˆ ê²€í†  â†’ ë°°í¬ â†’ ëª¨ë‹ˆí„°ë§",
            agents=["python_pro_01", "test_auto_01", "security_audit_01", 
                   "devops_exp_01", "perf_eng_01"],
            execution_mode=ExecutionMode.SEQUENTIAL,
            data_flow={
                "python_pro_01": "test_auto_01",
                "test_auto_01": "security_audit_01",
                "security_audit_01": "devops_exp_01", 
                "devops_exp_01": "perf_eng_01"
            }
        )
        
        # í’ˆì§ˆ ë³´ì¦ ì²´ì¸ (ë³‘ë ¬)
        qa_chain = AgentChain(
            id="quality_assurance",
            name="í’ˆì§ˆ ë³´ì¦ íŒŒì´í”„ë¼ì¸",
            description="í…ŒìŠ¤íŠ¸ ìë™í™”ì™€ ë³´ì•ˆ ê°ì‚¬ë¥¼ ë³‘ë ¬ë¡œ ìˆ˜í–‰",
            agents=["test_auto_01", "security_audit_01", "perf_eng_01"],
            execution_mode=ExecutionMode.PARALLEL,
            data_flow={}
        )
        
        # ì²´ì¸ ë“±ë¡
        for chain in [backend_chain, fullstack_chain, performance_chain, 
                     devops_chain, qa_chain]:
            self.agent_chains[chain.id] = chain
            
        # í˜‘ì—… ê·¸ë˜í”„ êµ¬ì„±
        self._build_collaboration_graph()
        
        logger.info(f"âœ… {len(self.agent_chains)}ê°œ í˜‘ì—… ì²´ì¸ ì„¤ì • ì™„ë£Œ")

    def _build_collaboration_graph(self):
        """í˜‘ì—… ê·¸ë˜í”„ êµ¬ì„±"""
        # ì—ì´ì „íŠ¸ ë…¸ë“œ ì¶”ê°€
        for agent_id, agent in self.agents.items():
            self.collaboration_graph.add_node(agent_id, agent=agent)
            
        # í˜‘ì—… ê´€ê³„ ì—£ì§€ ì¶”ê°€
        collaborations = [
            # ê°•í•œ í˜‘ì—… ê´€ê³„ (ì§ì ‘ì ì¸ ë°ì´í„° êµí™˜)
            ("sys_design_01", "backend_arch_01", {"weight": 0.9, "type": "direct"}),
            ("backend_arch_01", "python_pro_01", {"weight": 0.9, "type": "direct"}),
            ("python_pro_01", "db_opt_01", {"weight": 0.8, "type": "direct"}),
            ("python_pro_01", "test_auto_01", {"weight": 0.8, "type": "direct"}),
            ("test_auto_01", "security_audit_01", {"weight": 0.7, "type": "verification"}),
            ("security_audit_01", "perf_eng_01", {"weight": 0.6, "type": "optimization"}),
            ("devops_exp_01", "perf_eng_01", {"weight": 0.7, "type": "monitoring"}),
            
            # ì¤‘ê°„ í˜‘ì—… ê´€ê³„ (ê°„ì ‘ì ì¸ í”¼ë“œë°±)
            ("sys_design_01", "frontend_dev_01", {"weight": 0.7, "type": "design"}),
            ("frontend_dev_01", "test_auto_01", {"weight": 0.6, "type": "testing"}),
            ("db_opt_01", "perf_eng_01", {"weight": 0.8, "type": "optimization"}),
            ("security_audit_01", "devops_exp_01", {"weight": 0.6, "type": "deployment"}),
            
            # ì•½í•œ í˜‘ì—… ê´€ê³„ (ì •ë³´ ê³µìœ )
            ("sys_design_01", "security_audit_01", {"weight": 0.5, "type": "consultation"}),
            ("backend_arch_01", "devops_exp_01", {"weight": 0.5, "type": "consultation"}),
            ("frontend_dev_01", "security_audit_01", {"weight": 0.4, "type": "review"})
        ]
        
        self.collaboration_graph.add_edges_from(collaborations)

    async def intelligent_agent_selection(self, task: TaskDefinition) -> List[Tuple[str, float]]:
        """ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ ì„ íƒ - ì‘ì—…ì— ìµœì í™”ëœ ì—ì´ì „íŠ¸ ì¡°í•© ì¶”ì²œ"""
        logger.info(f"ğŸ¯ ì‘ì—… '{task.title}'ì— ëŒ€í•œ ìµœì  ì—ì´ì „íŠ¸ ì„ íƒ ì‹œì‘")
        
        candidates = []
        
        for agent_id, agent in self.agents.items():
            if agent.status == AgentStatus.OFFLINE:
                continue
                
            # ìŠ¤í‚¬ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
            skill_score = self._calculate_skill_match(agent, task.required_skills)
            
            # ê°€ìš©ì„± ì ìˆ˜ ê³„ì‚°
            availability_score = 1.0 - agent.load_factor
            
            # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
            performance_score = agent.success_rate * (1.0 / max(agent.average_response_time, 0.1))
            
            # ì—­í•  ë§¤ì¹­ ì ìˆ˜
            role_score = 1.0 if agent.role in task.required_agents else 0.5
            
            # ì¢…í•© ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
            total_score = (
                skill_score * 0.4 +
                availability_score * 0.2 + 
                performance_score * 0.2 +
                role_score * 0.2
            )
            
            candidates.append((agent_id, total_score))
            
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        candidates.sort(key=lambda x: x[1], reverse=True)
        
        logger.info(f"âœ… ìƒìœ„ {min(5, len(candidates))}ê°œ ì—ì´ì „íŠ¸ ì„ íƒ ì™„ë£Œ")
        return candidates[:5]

    def _calculate_skill_match(self, agent: SubAgent, required_skills: List[str]) -> float:
        """ìŠ¤í‚¬ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        if not required_skills:
            return 0.5  # ê¸°ë³¸ ì ìˆ˜
            
        total_match = 0.0
        total_skills = len(required_skills)
        
        for required_skill in required_skills:
            best_match = 0.0
            
            for capability in agent.capabilities:
                # í‚¤ì›Œë“œ ë§¤ì¹­
                keyword_matches = sum(1 for keyword in capability.keywords 
                                    if keyword.lower() in required_skill.lower())
                if keyword_matches > 0:
                    match_score = (keyword_matches / len(capability.keywords)) * capability.skill_level
                    best_match = max(best_match, match_score)
                    
                # ë„ë©”ì¸ ë§¤ì¹­
                if capability.domain.lower() in required_skill.lower():
                    best_match = max(best_match, capability.skill_level * 0.8)
                    
            total_match += best_match
            
        return total_match / total_skills

    async def create_agent_chain(self, task: TaskDefinition) -> AgentChain:
        """ìë™ ì—ì´ì „íŠ¸ ì²´ì¸ êµ¬ì„±"""
        logger.info(f"â›“ï¸ ì‘ì—… '{task.title}'ì„ ìœ„í•œ ì—ì´ì „íŠ¸ ì²´ì¸ ìë™ êµ¬ì„±")
        
        # 1. ê¸°ë³¸ ì—ì´ì „íŠ¸ ì„ íƒ
        agent_candidates = await self.intelligent_agent_selection(task)
        selected_agents = [agent_id for agent_id, _ in agent_candidates[:3]]
        
        # 2. ì˜ì¡´ì„± ë¶„ì„ìœ¼ë¡œ ì¶”ê°€ ì—ì´ì „íŠ¸ ê²°ì •
        additional_agents = self._analyze_dependencies(selected_agents, task)
        all_agents = selected_agents + additional_agents
        
        # 3. ì‹¤í–‰ ëª¨ë“œ ê²°ì •
        execution_mode = self._determine_execution_mode(all_agents, task)
        
        # 4. ë°ì´í„° í”Œë¡œìš° êµ¬ì„±
        data_flow = self._build_data_flow(all_agents, execution_mode)
        
        # 5. ì²´ì¸ ìƒì„±
        chain_id = f"auto_chain_{uuid.uuid4().hex[:8]}"
        chain = AgentChain(
            id=chain_id,
            name=f"ìë™ ìƒì„± ì²´ì¸: {task.title}",
            description=f"ì‘ì—… '{task.title}'ì„ ìœ„í•´ ìë™ ìƒì„±ëœ ì—ì´ì „íŠ¸ ì²´ì¸",
            agents=all_agents,
            execution_mode=execution_mode,
            data_flow=data_flow
        )
        
        self.agent_chains[chain_id] = chain
        logger.info(f"âœ… ì—ì´ì „íŠ¸ ì²´ì¸ '{chain_id}' ìƒì„± ì™„ë£Œ ({len(all_agents)}ê°œ ì—ì´ì „íŠ¸)")
        
        return chain

    def _analyze_dependencies(self, base_agents: List[str], task: TaskDefinition) -> List[str]:
        """ì˜ì¡´ì„± ë¶„ì„ì„ í†µí•œ ì¶”ê°€ ì—ì´ì „íŠ¸ ê²°ì •"""
        additional_agents = []
        
        # ì‘ì—… ìœ í˜•ë³„ ì˜ì¡´ì„± ê·œì¹™
        dependency_rules = {
            "development": ["test_auto_01", "security_audit_01"],
            "backend": ["db_opt_01", "security_audit_01"],
            "frontend": ["test_auto_01"],
            "database": ["security_audit_01", "perf_eng_01"],
            "deployment": ["devops_exp_01", "perf_eng_01"],
            "testing": ["python_pro_01"],
            "security": ["test_auto_01", "perf_eng_01"]
        }
        
        task_description_lower = task.description.lower()
        
        for category, required_agents in dependency_rules.items():
            if category in task_description_lower:
                for agent_id in required_agents:
                    if agent_id not in base_agents and agent_id in self.agents:
                        additional_agents.append(agent_id)
                        
        return list(set(additional_agents))  # ì¤‘ë³µ ì œê±°

    def _determine_execution_mode(self, agents: List[str], task: TaskDefinition) -> ExecutionMode:
        """ì‹¤í–‰ ëª¨ë“œ ìë™ ê²°ì •"""
        # ì—ì´ì „íŠ¸ ìˆ˜ì— ë”°ë¥¸ ê¸°ë³¸ ëª¨ë“œ
        if len(agents) <= 2:
            return ExecutionMode.SEQUENTIAL
        elif len(agents) <= 4:
            # ë…ë¦½ì  ì‘ì—…ì´ ê°€ëŠ¥í•œì§€ í™•ì¸
            if self._can_parallelize(agents):
                return ExecutionMode.PARALLEL
            else:
                return ExecutionMode.SEQUENTIAL
        else:
            return ExecutionMode.PIPELINE
            
    def _can_parallelize(self, agents: List[str]) -> bool:
        """ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        # ê·¸ë˜í”„ì—ì„œ ì—ì´ì „íŠ¸ ê°„ ê°•í•œ ì˜ì¡´ì„±ì´ ìˆëŠ”ì§€ í™•ì¸
        for i, agent1 in enumerate(agents):
            for agent2 in agents[i+1:]:
                if self.collaboration_graph.has_edge(agent1, agent2):
                    edge_data = self.collaboration_graph.get_edge_data(agent1, agent2)
                    if edge_data.get("weight", 0) > 0.7:  # ê°•í•œ ì˜ì¡´ì„±
                        return False
        return True

    def _build_data_flow(self, agents: List[str], mode: ExecutionMode) -> Dict[str, str]:
        """ë°ì´í„° í”Œë¡œìš° êµ¬ì„±"""
        data_flow = {}
        
        if mode == ExecutionMode.SEQUENTIAL:
            # ìˆœì°¨ ì‹¤í–‰: ì´ì „ â†’ ë‹¤ìŒ
            for i in range(len(agents) - 1):
                data_flow[agents[i]] = agents[i + 1]
                
        elif mode == ExecutionMode.PARALLEL:
            # ë³‘ë ¬ ì‹¤í–‰: ë°ì´í„° í”Œë¡œìš° ì—†ìŒ
            pass
            
        elif mode == ExecutionMode.PIPELINE:
            # íŒŒì´í”„ë¼ì¸: ê·¸ë˜í”„ ê¸°ë°˜ í”Œë¡œìš°
            for agent in agents:
                successors = []
                for successor in agents:
                    if (self.collaboration_graph.has_edge(agent, successor) and 
                        successor != agent):
                        successors.append(successor)
                        
                if successors:
                    data_flow[agent] = ",".join(successors)
                    
        return data_flow

    async def execute_workflow(self, chain_id: str, input_data: Dict[str, Any] = None) -> WorkflowExecution:
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        if chain_id not in self.agent_chains:
            raise ValueError(f"ì²´ì¸ '{chain_id}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
        chain = self.agent_chains[chain_id]
        logger.info(f"ğŸš€ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹œì‘: {chain.name}")
        
        execution = WorkflowExecution(
            id=f"exec_{uuid.uuid4().hex[:8]}",
            chain_id=chain_id,
            status="running",
            start_time=datetime.now()
        )
        
        self.active_workflows[execution.id] = execution
        
        try:
            if chain.execution_mode == ExecutionMode.SEQUENTIAL:
                await self._execute_sequential(execution, chain, input_data or {})
            elif chain.execution_mode == ExecutionMode.PARALLEL:
                await self._execute_parallel(execution, chain, input_data or {})
            elif chain.execution_mode == ExecutionMode.PIPELINE:
                await self._execute_pipeline(execution, chain, input_data or {})
                
            execution.status = "completed"
            
        except Exception as e:
            logger.error(f"âŒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            execution.status = "failed"
            execution.errors.append(str(e))
            
        execution.end_time = datetime.now()
        execution.metrics["total_duration"] = (execution.end_time - execution.start_time).total_seconds()
        
        logger.info(f"âœ… ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ: {execution.status}")
        return execution

    async def _execute_sequential(self, execution: WorkflowExecution, 
                                chain: AgentChain, input_data: Dict[str, Any]):
        """ìˆœì°¨ ì‹¤í–‰"""
        current_data = input_data
        
        for agent_id in chain.agents:
            if agent_id not in self.agents:
                continue
                
            execution.current_agent = agent_id
            agent = self.agents[agent_id]
            
            # ì—ì´ì „íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸
            agent.status = AgentStatus.BUSY
            agent.load_factor = min(1.0, agent.load_factor + 0.3)
            
            try:
                start_time = time.time()
                
                # ëª¨ì˜ ì‘ì—… ì‹¤í–‰
                result = await self._simulate_agent_execution(agent, current_data)
                
                execution_time = time.time() - start_time
                agent.average_response_time = (
                    (agent.average_response_time * agent.total_tasks + execution_time) /
                    (agent.total_tasks + 1)
                )
                
                agent.total_tasks += 1
                agent.completed_tasks += 1
                agent.last_activity = datetime.now()
                
                execution.results[agent_id] = result
                execution.completed_agents.append(agent_id)
                
                # ë‹¤ìŒ ì—ì´ì „íŠ¸ë¡œ ë°ì´í„° ì „ë‹¬
                current_data = result.get("output", current_data)
                
            except Exception as e:
                agent.failed_tasks += 1
                execution.errors.append(f"{agent_id}: {str(e)}")
                raise
                
            finally:
                agent.status = AgentStatus.IDLE
                agent.load_factor = max(0.0, agent.load_factor - 0.3)

    async def _execute_parallel(self, execution: WorkflowExecution,
                              chain: AgentChain, input_data: Dict[str, Any]):
        """ë³‘ë ¬ ì‹¤í–‰"""
        tasks = []
        
        for agent_id in chain.agents:
            if agent_id in self.agents:
                tasks.append(self._execute_agent_task(agent_id, input_data))
                
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for i, (agent_id, result) in enumerate(zip(chain.agents, results)):
            if isinstance(result, Exception):
                execution.errors.append(f"{agent_id}: {str(result)}")
            else:
                execution.results[agent_id] = result
                execution.completed_agents.append(agent_id)

    async def _execute_pipeline(self, execution: WorkflowExecution,
                              chain: AgentChain, input_data: Dict[str, Any]):
        """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        # í† í´ë¡œì§€ ì •ë ¬ë¡œ ì‹¤í–‰ ìˆœì„œ ê²°ì •
        execution_order = self._topological_sort(chain.agents, chain.data_flow)
        
        agent_results = {}
        
        for agent_id in execution_order:
            if agent_id not in self.agents:
                continue
                
            # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
            agent_input = input_data.copy()
            
            # ì´ì „ ì—ì´ì „íŠ¸ ê²°ê³¼ ë³‘í•©
            for prev_agent in execution.completed_agents:
                if prev_agent in agent_results:
                    agent_input.update(agent_results[prev_agent].get("output", {}))
                    
            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            result = await self._execute_agent_task(agent_id, agent_input)
            agent_results[agent_id] = result
            execution.results[agent_id] = result
            execution.completed_agents.append(agent_id)

    def _topological_sort(self, agents: List[str], data_flow: Dict[str, str]) -> List[str]:
        """í† í´ë¡œì§€ ì •ë ¬ (ì˜ì¡´ì„± ìˆœì„œ ê²°ì •)"""
        # ê°„ë‹¨í•œ í† í´ë¡œì§€ ì •ë ¬ êµ¬í˜„
        in_degree = {agent: 0 for agent in agents}
        graph = {agent: [] for agent in agents}
        
        # ê·¸ë˜í”„ êµ¬ì„±
        for source, targets in data_flow.items():
            if source in agents:
                for target in targets.split(","):
                    target = target.strip()
                    if target in agents:
                        graph[source].append(target)
                        in_degree[target] += 1
                        
        # í† í´ë¡œì§€ ì •ë ¬
        queue = [agent for agent in agents if in_degree[agent] == 0]
        result = []
        
        while queue:
            current = queue.pop(0)
            result.append(current)
            
            for neighbor in graph[current]:
                in_degree[neighbor] -= 1
                if in_degree[neighbor] == 0:
                    queue.append(neighbor)
                    
        return result if len(result) == len(agents) else agents

    async def _execute_agent_task(self, agent_id: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ê°œë³„ ì—ì´ì „íŠ¸ ì‘ì—… ì‹¤í–‰"""
        agent = self.agents[agent_id]
        agent.status = AgentStatus.BUSY
        
        try:
            start_time = time.time()
            result = await self._simulate_agent_execution(agent, input_data)
            execution_time = time.time() - start_time
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            agent.average_response_time = (
                (agent.average_response_time * agent.total_tasks + execution_time) /
                (agent.total_tasks + 1)
            )
            agent.total_tasks += 1
            agent.completed_tasks += 1
            agent.last_activity = datetime.now()
            
            return result
            
        except Exception as e:
            agent.failed_tasks += 1
            raise
        finally:
            agent.status = AgentStatus.IDLE

    async def _simulate_agent_execution(self, agent: SubAgent, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜"""
        # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì—¬ê¸°ì„œ ì‹¤ì œ ì—ì´ì „íŠ¸ ë¡œì§ì„ í˜¸ì¶œ
        await asyncio.sleep(0.5 + np.random.exponential(0.5))  # ì‹¤í–‰ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        
        # ì—­í• ë³„ ëª¨ì˜ ì¶œë ¥ ìƒì„±
        if agent.role == AgentRole.PYTHON_PRO:
            return {
                "status": "success",
                "output": {
                    "code_quality": "excellent",
                    "performance": "optimized",
                    "test_coverage": 0.95,
                    "generated_files": ["main.py", "utils.py", "tests.py"]
                },
                "duration": np.random.uniform(1.0, 3.0),
                "agent_id": agent.id
            }
            
        elif agent.role == AgentRole.BACKEND_ARCHITECT:
            return {
                "status": "success",
                "output": {
                    "architecture": "microservices",
                    "api_design": "REST + GraphQL",
                    "database_schema": "optimized",
                    "scalability": "horizontal",
                    "documentation": ["api_spec.yaml", "architecture_diagram.png"]
                },
                "duration": np.random.uniform(2.0, 5.0),
                "agent_id": agent.id
            }
            
        elif agent.role == AgentRole.FRONTEND_DEVELOPER:
            return {
                "status": "success", 
                "output": {
                    "ui_components": "React + TypeScript",
                    "responsive_design": True,
                    "accessibility": "WCAG 2.1 AA",
                    "performance_score": 0.92,
                    "generated_files": ["components/", "pages/", "styles/"]
                },
                "duration": np.random.uniform(1.5, 4.0),
                "agent_id": agent.id
            }
            
        elif agent.role == AgentRole.TEST_AUTOMATOR:
            return {
                "status": "success",
                "output": {
                    "test_coverage": 0.94,
                    "test_results": {"passed": 45, "failed": 2, "skipped": 1},
                    "performance_tests": "completed",
                    "e2e_tests": "passed",
                    "generated_reports": ["coverage.html", "test_results.xml"]
                },
                "duration": np.random.uniform(3.0, 6.0),
                "agent_id": agent.id
            }
            
        elif agent.role == AgentRole.SECURITY_AUDITOR:
            return {
                "status": "success",
                "output": {
                    "vulnerabilities": {"high": 0, "medium": 1, "low": 3},
                    "security_score": 0.88,
                    "compliance": "OWASP Top 10",
                    "recommendations": ["Update dependency X", "Add rate limiting"],
                    "security_report": "security_audit.pdf"
                },
                "duration": np.random.uniform(2.0, 4.0), 
                "agent_id": agent.id
            }
            
        elif agent.role == AgentRole.PERFORMANCE_ENGINEER:
            return {
                "status": "success",
                "output": {
                    "performance_score": 0.91,
                    "load_test_results": "passed",
                    "bottlenecks": ["database query optimization needed"],
                    "optimization_suggestions": ["Add caching", "Optimize queries"],
                    "performance_report": "performance_analysis.html"
                },
                "duration": np.random.uniform(2.5, 5.0),
                "agent_id": agent.id
            }
            
        else:
            return {
                "status": "success",
                "output": {
                    "task_completed": True,
                    "agent_role": agent.role.value,
                    "input_processed": len(input_data),
                    "execution_context": "simulated"
                },
                "duration": np.random.uniform(1.0, 3.0),
                "agent_id": agent.id
            }

    def analyze_agent_performance(self) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ì„±ëŠ¥ ë¶„ì„"""
        logger.info("ğŸ“Š ì—ì´ì „íŠ¸ ì„±ëŠ¥ ë¶„ì„ ì‹œì‘")
        
        analysis = {
            "timestamp": datetime.now().isoformat(),
            "total_agents": len(self.agents),
            "performance_summary": {},
            "top_performers": [],
            "underperformers": [],
            "collaboration_metrics": {},
            "recommendations": []
        }
        
        # ê°œë³„ ì—ì´ì „íŠ¸ ì„±ëŠ¥ ê³„ì‚°
        performance_scores = {}
        
        for agent_id, agent in self.agents.items():
            if agent.total_tasks > 0:
                success_rate = agent.completed_tasks / agent.total_tasks
                efficiency_score = 1.0 / max(agent.average_response_time, 0.1)
                load_score = 1.0 - agent.load_factor
                
                overall_score = (success_rate * 0.5 + 
                               efficiency_score * 0.3 + 
                               load_score * 0.2)
                               
                performance_scores[agent_id] = {
                    "agent_name": agent.name,
                    "role": agent.role.value,
                    "overall_score": overall_score,
                    "success_rate": success_rate,
                    "avg_response_time": agent.average_response_time,
                    "total_tasks": agent.total_tasks,
                    "current_load": agent.load_factor,
                    "status": agent.status.value
                }
        
        # ìƒìœ„/í•˜ìœ„ ì„±ëŠ¥ì ì‹ë³„
        sorted_agents = sorted(performance_scores.items(), 
                              key=lambda x: x[1]["overall_score"], reverse=True)
        
        analysis["top_performers"] = [
            {"agent_id": agent_id, **metrics} 
            for agent_id, metrics in sorted_agents[:3]
        ]
        
        analysis["underperformers"] = [
            {"agent_id": agent_id, **metrics}
            for agent_id, metrics in sorted_agents[-2:]
            if metrics["overall_score"] < 0.7
        ]
        
        # í˜‘ì—… ë©”íŠ¸ë¦­
        analysis["collaboration_metrics"] = {
            "total_chains": len(self.agent_chains),
            "active_workflows": len(self.active_workflows),
            "collaboration_patterns": len(self.collaboration_graph.edges()),
            "most_connected_agent": self._find_most_connected_agent()
        }
        
        # ì„±ëŠ¥ ìš”ì•½
        if performance_scores:
            scores = [metrics["overall_score"] for metrics in performance_scores.values()]
            analysis["performance_summary"] = {
                "average_score": np.mean(scores),
                "median_score": np.median(scores),
                "std_deviation": np.std(scores),
                "total_tasks_completed": sum(agent.completed_tasks for agent in self.agents.values()),
                "total_tasks_failed": sum(agent.failed_tasks for agent in self.agents.values())
            }
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        if analysis["underperformers"]:
            analysis["recommendations"].append("ì„±ëŠ¥ì´ ë‚®ì€ ì—ì´ì „íŠ¸ë“¤ì˜ ë¡œë“œ ë°¸ëŸ°ì‹±ì„ ê²€í† í•˜ì„¸ìš”")
            
        if analysis["performance_summary"].get("average_score", 0) < 0.8:
            analysis["recommendations"].append("ì „ë°˜ì ì¸ ì‹œìŠ¤í…œ ì„±ëŠ¥ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            
        if len(analysis["top_performers"]) < 3:
            analysis["recommendations"].append("ê³ ì„±ëŠ¥ ì—ì´ì „íŠ¸ì˜ ì‘ì—… íŒ¨í„´ì„ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì— ì ìš©í•˜ì„¸ìš”")
        
        logger.info("âœ… ì—ì´ì „íŠ¸ ì„±ëŠ¥ ë¶„ì„ ì™„ë£Œ")
        return analysis

    def _find_most_connected_agent(self) -> str:
        """ê°€ì¥ ì—°ê²°ì´ ë§ì€ ì—ì´ì „íŠ¸ ì°¾ê¸°"""
        if not self.collaboration_graph.nodes():
            return "none"
            
        centrality = nx.degree_centrality(self.collaboration_graph)
        most_connected = max(centrality.items(), key=lambda x: x[1])
        return most_connected[0]

    def optimize_agent_distribution(self) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ë¶„ë°° ìµœì í™”"""
        logger.info("âš–ï¸ ì—ì´ì „íŠ¸ ë¡œë“œ ë°¸ëŸ°ì‹± ìµœì í™” ì‹œì‘")
        
        optimization_result = {
            "timestamp": datetime.now().isoformat(),
            "current_loads": {},
            "suggested_redistributions": [],
            "efficiency_improvement": 0.0,
            "actions_taken": []
        }
        
        # í˜„ì¬ ë¡œë“œ ìƒíƒœ ìˆ˜ì§‘
        for agent_id, agent in self.agents.items():
            optimization_result["current_loads"][agent_id] = {
                "load_factor": agent.load_factor,
                "status": agent.status.value,
                "avg_response_time": agent.average_response_time
            }
        
        # ê³¼ë¶€í•˜ ë° ìœ íœ´ ì—ì´ì „íŠ¸ ì‹ë³„
        overloaded_agents = [
            agent_id for agent_id, agent in self.agents.items()
            if agent.load_factor > 0.8
        ]
        
        idle_agents = [
            agent_id for agent_id, agent in self.agents.items() 
            if agent.load_factor < 0.3 and agent.status == AgentStatus.IDLE
        ]
        
        # ì¬ë¶„ë°° ì œì•ˆ
        if overloaded_agents and idle_agents:
            for overloaded in overloaded_agents:
                for idle in idle_agents:
                    # ì—­ëŸ‰ í˜¸í™˜ì„± í™•ì¸
                    if self._check_capability_compatibility(overloaded, idle):
                        optimization_result["suggested_redistributions"].append({
                            "from": overloaded,
                            "to": idle,
                            "estimated_improvement": 0.2,
                            "compatibility_score": 0.8
                        })
        
        # ìë™ ë¡œë“œ ì¡°ì • (ì‹œë®¬ë ˆì´ì…˜)
        total_improvement = 0.0
        for redistribution in optimization_result["suggested_redistributions"]:
            # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì—¬ê¸°ì„œ ì‘ì—… ì¬ë¶„ë°° ì‹¤í–‰
            total_improvement += redistribution["estimated_improvement"]
            optimization_result["actions_taken"].append(
                f"ì‘ì—… ì¼ë¶€ë¥¼ {redistribution['from']}ì—ì„œ {redistribution['to']}ë¡œ ì´ë™"
            )
        
        optimization_result["efficiency_improvement"] = total_improvement
        
        logger.info(f"âœ… ë¡œë“œ ë°¸ëŸ°ì‹± ìµœì í™” ì™„ë£Œ (íš¨ìœ¨ì„± ê°œì„ : {total_improvement:.2f})")
        return optimization_result

    def _check_capability_compatibility(self, agent1_id: str, agent2_id: str) -> bool:
        """ì—ì´ì „íŠ¸ ê°„ ì—­ëŸ‰ í˜¸í™˜ì„± í™•ì¸"""
        agent1 = self.agents[agent1_id]
        agent2 = self.agents[agent2_id]
        
        # ë„ë©”ì¸ ê²¹ì¹˜ëŠ” ë¶€ë¶„ í™•ì¸
        domains1 = {cap.domain for cap in agent1.capabilities}
        domains2 = {cap.domain for cap in agent2.capabilities}
        
        return len(domains1.intersection(domains2)) > 0

    async def dynamic_agent_replacement(self, failing_agent_id: str) -> Dict[str, Any]:
        """ë™ì  ì—ì´ì „íŠ¸ êµì²´"""
        logger.info(f"ğŸ”„ ì—ì´ì „íŠ¸ '{failing_agent_id}' ë™ì  êµì²´ ì‹œì‘")
        
        if failing_agent_id not in self.agents:
            raise ValueError(f"ì—ì´ì „íŠ¸ '{failing_agent_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        failing_agent = self.agents[failing_agent_id]
        
        # ëŒ€ì²´ ì—ì´ì „íŠ¸ í›„ë³´ ì°¾ê¸°
        replacement_candidates = []
        
        for agent_id, agent in self.agents.items():
            if (agent_id != failing_agent_id and 
                agent.status != AgentStatus.OFFLINE and
                agent.load_factor < 0.7):
                
                # ì—­ëŸ‰ ìœ ì‚¬ë„ ê³„ì‚°
                similarity = self._calculate_capability_similarity(failing_agent, agent)
                
                if similarity > 0.5:  # 50% ì´ìƒ ìœ ì‚¬
                    replacement_candidates.append({
                        "agent_id": agent_id,
                        "agent_name": agent.name,
                        "similarity": similarity,
                        "current_load": agent.load_factor,
                        "success_rate": agent.success_rate
                    })
        
        # ìµœì  ëŒ€ì²´ì ì„ íƒ
        if replacement_candidates:
            replacement_candidates.sort(
                key=lambda x: (x["similarity"], -x["current_load"], x["success_rate"]),
                reverse=True
            )
            
            best_replacement = replacement_candidates[0]
            
            # í™œì„± ì›Œí¬í”Œë¡œìš°ì—ì„œ ì—ì´ì „íŠ¸ êµì²´
            replacement_count = 0
            for workflow in self.active_workflows.values():
                if failing_agent_id in workflow.completed_agents:
                    continue  # ì´ë¯¸ ì™„ë£Œëœ ì‘ì—…ì€ êµì²´í•˜ì§€ ì•ŠìŒ
                    
                chain = self.agent_chains[workflow.chain_id]
                if failing_agent_id in chain.agents:
                    # ì—ì´ì „íŠ¸ êµì²´
                    agent_index = chain.agents.index(failing_agent_id)
                    chain.agents[agent_index] = best_replacement["agent_id"]
                    replacement_count += 1
            
            # ì‹¤íŒ¨í•œ ì—ì´ì „íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸
            failing_agent.status = AgentStatus.ERROR
            
            result = {
                "timestamp": datetime.now().isoformat(),
                "failing_agent": failing_agent_id,
                "replacement_agent": best_replacement["agent_id"],
                "similarity_score": best_replacement["similarity"],
                "workflows_affected": replacement_count,
                "status": "success"
            }
            
            logger.info(f"âœ… ì—ì´ì „íŠ¸ êµì²´ ì™„ë£Œ: {failing_agent_id} â†’ {best_replacement['agent_id']}")
            
        else:
            result = {
                "timestamp": datetime.now().isoformat(),
                "failing_agent": failing_agent_id,
                "replacement_agent": None,
                "status": "no_suitable_replacement",
                "message": "ì í•©í•œ ëŒ€ì²´ ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            }
            
            logger.warning(f"âš ï¸ ì—ì´ì „íŠ¸ '{failing_agent_id}' êµì²´ ì‹¤íŒ¨: ì í•©í•œ ëŒ€ì²´ì ì—†ìŒ")
        
        return result

    def _calculate_capability_similarity(self, agent1: SubAgent, agent2: SubAgent) -> float:
        """ì—ì´ì „íŠ¸ ê°„ ì—­ëŸ‰ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not agent1.capabilities or not agent2.capabilities:
            return 0.0
        
        # ë„ë©”ì¸ ìœ ì‚¬ë„
        domains1 = {cap.domain for cap in agent1.capabilities}
        domains2 = {cap.domain for cap in agent2.capabilities}
        domain_similarity = len(domains1.intersection(domains2)) / len(domains1.union(domains2))
        
        # í‚¤ì›Œë“œ ìœ ì‚¬ë„
        keywords1 = set()
        keywords2 = set()
        
        for cap in agent1.capabilities:
            keywords1.update(cap.keywords)
        for cap in agent2.capabilities:
            keywords2.update(cap.keywords)
            
        if keywords1 and keywords2:
            keyword_similarity = len(keywords1.intersection(keywords2)) / len(keywords1.union(keywords2))
        else:
            keyword_similarity = 0.0
        
        # ì¢…í•© ìœ ì‚¬ë„ (ë„ë©”ì¸ 60%, í‚¤ì›Œë“œ 40%)
        return domain_similarity * 0.6 + keyword_similarity * 0.4

    def get_workflow_status(self, execution_id: str) -> Dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì¡°íšŒ"""
        if execution_id not in self.active_workflows:
            return {"error": f"ì‹¤í–‰ ID '{execution_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        execution = self.active_workflows[execution_id]
        chain = self.agent_chains[execution.chain_id]
        
        progress = len(execution.completed_agents) / len(chain.agents) if chain.agents else 0.0
        
        return {
            "execution_id": execution_id,
            "chain_name": chain.name,
            "status": execution.status,
            "progress": progress,
            "current_agent": execution.current_agent,
            "completed_agents": execution.completed_agents,
            "total_agents": len(chain.agents),
            "start_time": execution.start_time.isoformat(),
            "duration": (datetime.now() - execution.start_time).total_seconds(),
            "errors": execution.errors,
            "results_count": len(execution.results)
        }

    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """ì¢…í•© ì‹œìŠ¤í…œ ë¦¬í¬íŠ¸ ìƒì„±"""
        logger.info("ğŸ“‹ ì¢…í•© ì‹œìŠ¤í…œ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "system_overview": {
                "total_agents": len(self.agents),
                "total_chains": len(self.agent_chains),
                "active_workflows": len(self.active_workflows),
                "collaboration_edges": len(self.collaboration_graph.edges())
            },
            "agent_summary": {},
            "performance_analysis": self.analyze_agent_performance(),
            "optimization_suggestions": self.optimize_agent_distribution(),
            "health_status": {},
            "recommendations": []
        }
        
        # ì—ì´ì „íŠ¸ ìš”ì•½
        status_counts = {}
        for agent in self.agents.values():
            status = agent.status.value
            status_counts[status] = status_counts.get(status, 0) + 1
        
        report["agent_summary"] = {
            "status_distribution": status_counts,
            "average_load": np.mean([agent.load_factor for agent in self.agents.values()]),
            "total_tasks_completed": sum(agent.completed_tasks for agent in self.agents.values()),
            "total_tasks_failed": sum(agent.failed_tasks for agent in self.agents.values()),
            "average_success_rate": np.mean([
                agent.completed_tasks / max(agent.total_tasks, 1) 
                for agent in self.agents.values()
            ])
        }
        
        # ì‹œìŠ¤í…œ ê±´ê°•ë„
        healthy_agents = sum(1 for agent in self.agents.values() 
                           if agent.status in [AgentStatus.IDLE, AgentStatus.BUSY])
        
        report["health_status"] = {
            "overall_health": healthy_agents / len(self.agents),
            "healthy_agents": healthy_agents,
            "error_agents": sum(1 for agent in self.agents.values() 
                              if agent.status == AgentStatus.ERROR),
            "system_status": "healthy" if healthy_agents / len(self.agents) > 0.8 else "degraded"
        }
        
        # ì¢…í•© ê¶Œì¥ì‚¬í•­
        if report["health_status"]["overall_health"] < 0.8:
            report["recommendations"].append("ì‹œìŠ¤í…œ ì „ë°˜ì ì¸ ê±´ê°•ë„ ê°œì„  í•„ìš”")
            
        if report["agent_summary"]["average_load"] > 0.8:
            report["recommendations"].append("ì—ì´ì „íŠ¸ ë¡œë“œ ë¶„ì‚° ìµœì í™” í•„ìš”")
            
        if report["agent_summary"]["average_success_rate"] < 0.9:
            report["recommendations"].append("ì—ì´ì „íŠ¸ ì„±ê³µë¥  ê°œì„  í•„ìš”")
        
        logger.info("âœ… ì¢…í•© ì‹œìŠ¤í…œ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
        return report

def create_usage_examples():
    """ì‚¬ìš© ì˜ˆì‹œ ìƒì„±"""
    return """
# Advanced Meta Agent System ì‚¬ìš© ê°€ì´ë“œ

## 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”
```python
meta_system = MetaAgentSystem()
print(f"ì´ˆê¸°í™” ì™„ë£Œ: {len(meta_system.agents)}ê°œ ì—ì´ì „íŠ¸, {len(meta_system.agent_chains)}ê°œ ì²´ì¸")
```

## 2. ì‘ì—… ì •ì˜ ë° ìë™ ì—ì´ì „íŠ¸ ì„ íƒ
```python
task = TaskDefinition(
    id="task_001",
    title="ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ",
    description="Python Flask ë°±ì—”ë“œì™€ React í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ",
    priority=8,
    estimated_duration=3600,
    required_skills=["python", "react", "database", "testing"],
    required_agents=[AgentRole.PYTHON_PRO, AgentRole.FRONTEND_DEVELOPER]
)

# ìµœì  ì—ì´ì „íŠ¸ ì„ íƒ
candidates = await meta_system.intelligent_agent_selection(task)
print("ì¶”ì²œ ì—ì´ì „íŠ¸:", [f"{agent_id} (ì ìˆ˜: {score:.2f})" for agent_id, score in candidates])
```

## 3. ìë™ ì—ì´ì „íŠ¸ ì²´ì¸ ìƒì„± ë° ì‹¤í–‰
```python
# ìë™ ì²´ì¸ ìƒì„±
chain = await meta_system.create_agent_chain(task)
print(f"ìƒì„±ëœ ì²´ì¸: {chain.name} ({len(chain.agents)}ê°œ ì—ì´ì „íŠ¸)")

# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
execution = await meta_system.execute_workflow(chain.id, {
    "project_name": "my-web-app",
    "tech_stack": "Flask + React",
    "database": "PostgreSQL"
})

print(f"ì‹¤í–‰ ê²°ê³¼: {execution.status}")
print(f"ì™„ë£Œëœ ì—ì´ì „íŠ¸: {len(execution.completed_agents)}/{len(chain.agents)}")
```

## 4. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
```python
# ì›Œí¬í”Œë¡œìš° ìƒíƒœ í™•ì¸
status = meta_system.get_workflow_status(execution.id)
print(f"ì§„í–‰ë¥ : {status['progress']*100:.1f}%")
print(f"í˜„ì¬ ì—ì´ì „íŠ¸: {status['current_agent']}")

# ì„±ëŠ¥ ë¶„ì„
performance = meta_system.analyze_agent_performance()
print("ìƒìœ„ ì„±ëŠ¥ì:", [p['agent_name'] for p in performance['top_performers']])
```

## 5. ë™ì  ìµœì í™”
```python
# ë¡œë“œ ë°¸ëŸ°ì‹± ìµœì í™”
optimization = meta_system.optimize_agent_distribution()
print(f"íš¨ìœ¨ì„± ê°œì„ : {optimization['efficiency_improvement']:.2f}")

# ì‹¤íŒ¨í•œ ì—ì´ì „íŠ¸ êµì²´
if "python_pro_01" in meta_system.agents:
    replacement = await meta_system.dynamic_agent_replacement("python_pro_01")
    print(f"êµì²´ ê²°ê³¼: {replacement['status']}")
```

## 6. ì‚¬ì „ ì •ì˜ í˜‘ì—… íŒ¨í„´ ì‚¬ìš©
```python
# ë°±ì—”ë“œ ê°œë°œ íŒŒì´í”„ë¼ì¸
backend_execution = await meta_system.execute_workflow("backend_development", {
    "project_type": "microservice",
    "database": "MongoDB",
    "api_style": "GraphQL"
})

# í’€ìŠ¤íƒ ê°œë°œ íŒŒì´í”„ë¼ì¸  
fullstack_execution = await meta_system.execute_workflow("fullstack_development", {
    "frontend": "Next.js",
    "backend": "FastAPI", 
    "database": "Supabase"
})
```

## 7. ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
```python
report = meta_system.generate_comprehensive_report()
print(f"ì‹œìŠ¤í…œ ê±´ê°•ë„: {report['health_status']['overall_health']:.2f}")
print(f"í‰ê·  ì„±ê³µë¥ : {report['agent_summary']['average_success_rate']:.2f}")
print("ê¶Œì¥ì‚¬í•­:", report['recommendations'])
```

## 8. ê³ ê¸‰ í˜‘ì—… íŒ¨í„´
```python
# ì‚¬ìš©ì ì •ì˜ ì²´ì¸ ìƒì„±
custom_chain = AgentChain(
    id="custom_security_review",
    name="ë³´ì•ˆ ì¤‘ì‹¬ ì½”ë“œ ë¦¬ë·°",
    description="ê°œë°œ â†’ í…ŒìŠ¤íŠ¸ â†’ ë³´ì•ˆ ê°ì‚¬ â†’ ì„±ëŠ¥ ê²€í† ",
    agents=["python_pro_01", "test_auto_01", "security_audit_01", "perf_eng_01"],
    execution_mode=ExecutionMode.SEQUENTIAL,
    data_flow={
        "python_pro_01": "test_auto_01",
        "test_auto_01": "security_audit_01", 
        "security_audit_01": "perf_eng_01"
    }
)

meta_system.agent_chains["custom_security"] = custom_chain

# ë³‘ë ¬ í’ˆì§ˆ ê²€ì¦
parallel_execution = await meta_system.execute_workflow("quality_assurance", {
    "code_base": "/path/to/project",
    "test_scope": "full",
    "security_level": "strict"
})
```

## ì£¼ìš” íŠ¹ì§•:
- âœ… **ìë™ ì—ì´ì „íŠ¸ ì„ íƒ**: ì‘ì—… ìš”êµ¬ì‚¬í•­ì— ë”°ë¥¸ ìµœì  ì—ì´ì „íŠ¸ ì¡°í•©
- âœ… **ë™ì  ì›Œí¬í”Œë¡œìš°**: ì‹¤ì‹œê°„ ìƒí™©ì— ë”°ë¥¸ ì‹¤í–‰ ê³„íš ì¡°ì •
- âœ… **ì§€ëŠ¥í˜• ë¡œë“œ ë°¸ëŸ°ì‹±**: ì—ì´ì „íŠ¸ ë¶€í•˜ ë¶„ì‚° ë° ì„±ëŠ¥ ìµœì í™”
- âœ… **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: ì›Œí¬í”Œë¡œìš° ì§„í–‰ ìƒí™© ë° ì—ì´ì „íŠ¸ ìƒíƒœ ì¶”ì 
- âœ… **ìë™ ë³µêµ¬**: ì‹¤íŒ¨í•œ ì—ì´ì „íŠ¸ ê°ì§€ ë° ëŒ€ì²´
- âœ… **í˜‘ì—… ìµœì í™”**: ì—ì´ì „íŠ¸ ê°„ ë°ì´í„° í”Œë¡œìš° ë° ì˜ì¡´ì„± ê´€ë¦¬
"""

if __name__ == "__main__":
    async def demo():
        print("ğŸš€ Advanced Meta Agent System ë°ëª¨ ì‹œì‘")
        print("=" * 60)
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        meta_system = MetaAgentSystem()
        
        # ì‘ì—… ì •ì˜
        demo_task = TaskDefinition(
            id="demo_task",
            title="Python ì›¹ API ê°œë°œ ë° ë°°í¬",
            description="FastAPI ê¸°ë°˜ REST API ê°œë°œ, í…ŒìŠ¤íŠ¸, ë³´ì•ˆ ê²€í† , ë°°í¬",
            priority=9,
            estimated_duration=1800,
            required_skills=["python", "api", "testing", "security", "deployment"],
            required_agents=[AgentRole.PYTHON_PRO, AgentRole.TEST_AUTOMATOR, 
                           AgentRole.SECURITY_AUDITOR, AgentRole.DEVOPS_EXPERT]
        )
        
        print("\nğŸ¯ ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ ì„ íƒ:")
        candidates = await meta_system.intelligent_agent_selection(demo_task)
        for agent_id, score in candidates[:3]:
            agent = meta_system.agents[agent_id]
            print(f"- {agent.name} ({agent.role.value}): {score:.3f}")
        
        print("\nâ›“ï¸ ìë™ ì—ì´ì „íŠ¸ ì²´ì¸ ìƒì„±:")
        chain = await meta_system.create_agent_chain(demo_task)
        print(f"ì²´ì¸ëª…: {chain.name}")
        print(f"ì‹¤í–‰ ëª¨ë“œ: {chain.execution_mode.value}")
        print(f"ì—ì´ì „íŠ¸: {[meta_system.agents[aid].name for aid in chain.agents]}")
        
        print("\nğŸš€ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰:")
        execution = await meta_system.execute_workflow(chain.id, {
            "project_name": "demo-api",
            "framework": "FastAPI",
            "database": "PostgreSQL"
        })
        
        print(f"ì‹¤í–‰ ìƒíƒœ: {execution.status}")
        print(f"ì™„ë£Œëœ ë‹¨ê³„: {len(execution.completed_agents)}/{len(chain.agents)}")
        print(f"ì‹¤í–‰ ì‹œê°„: {execution.metrics.get('total_duration', 0):.2f}ì´ˆ")
        
        print("\nğŸ“Š ì„±ëŠ¥ ë¶„ì„:")
        performance = meta_system.analyze_agent_performance()
        print(f"í‰ê·  ì„±ëŠ¥ ì ìˆ˜: {performance['performance_summary']['average_score']:.3f}")
        print("ìƒìœ„ ì„±ëŠ¥ì:")
        for performer in performance['top_performers'][:2]:
            print(f"- {performer['agent_name']}: {performer['overall_score']:.3f}")
        
        print("\nâš–ï¸ ì‹œìŠ¤í…œ ìµœì í™”:")
        optimization = meta_system.optimize_agent_distribution()
        print(f"íš¨ìœ¨ì„± ê°œì„ : {optimization['efficiency_improvement']:.2f}")
        
        print("\nğŸ“‹ ì¢…í•© ë¦¬í¬íŠ¸:")
        report = meta_system.generate_comprehensive_report()
        print(f"ì‹œìŠ¤í…œ ê±´ê°•ë„: {report['health_status']['overall_health']:.1%}")
        print(f"ì´ ì™„ë£Œ ì‘ì—…: {report['agent_summary']['total_tasks_completed']}")
        print(f"í‰ê·  ì„±ê³µë¥ : {report['agent_summary']['average_success_rate']:.1%}")
        
        if report['recommendations']:
            print("ê¶Œì¥ì‚¬í•­:")
            for rec in report['recommendations'][:2]:
                print(f"- {rec}")
        
        print("\nâœ… ë°ëª¨ ì™„ë£Œ!")
        print("\nì‚¬ìš© ê°€ì´ë“œ:")
        print("=" * 60)
        print(create_usage_examples())
    
    # ë°ëª¨ ì‹¤í–‰
    asyncio.run(demo())